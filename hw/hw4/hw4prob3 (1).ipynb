{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4prob3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGnlRWvkY-2c"
      },
      "source": [
        "In this problem we will use the BERT model for sentiment analysis. We will start with a pre-trained BERT model and fine-tune it on a dataset of Google Play store reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmj22-TcZMef"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_7Tz0-pK69"
      },
      "source": [
        "!pip install -q -U watermark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjsbi1u3QFEM"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqoaFpVpoM8",
        "outputId": "a2f7b436-03c7-4dbf-e6ac-56421652545b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPython 3.6.9\n",
            "IPython 5.5.0\n",
            "\n",
            "numpy 1.18.5\n",
            "pandas 1.1.3\n",
            "torch 1.6.0+cu101\n",
            "transformers 3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "Download the Google Play app reviews dataset using the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgPRhuMzi9ot",
        "outputId": "a7f3c718-cfc2-462b-aefe-1f21e7d5ab66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 42.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "7.17MB [00:00, 33.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7GO8vXo6IVO"
      },
      "source": [
        "Here is how it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKLyKc7I6Qp",
        "outputId": "e2e48c34-b3f6-4c73-84c1-e025bf5b7d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           userName  ...      appId\n",
              "0     Andrew Thomas  ...  com.anydo\n",
              "1      Craig Haines  ...  com.anydo\n",
              "2     steven adkins  ...  com.anydo\n",
              "3  Lars Panzerbjørn  ...  com.anydo\n",
              "4     Scott Prewitt  ...  com.anydo\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AiAdQ3j6SDe"
      },
      "source": [
        "Let's first check the size of the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB2jE6am7Dpo",
        "outputId": "8e67d7c7-4b80-49f5-eeda-60afdd642c1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q1. How many samples are there in this dataset? \n",
        "print(\"The size of the dataset:\",len(df))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the dataset: 15746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwh_rW4Efhs3",
        "outputId": "d50a9588-6af3-409e-c942-05368dc4139b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# TODO: Q2. Plot a histogram of review scores. These can be accessed in the df.score field in the above dataframe. Which score is the most common?\n",
        "df[\"score\"].hist(bins=40)\n",
        "print(\"3 is the the most common value of the column score.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 is the the most common value of the column score.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZM0GKviobjM"
      },
      "source": [
        "If correctly plotted, you should be able to see that this is a somewhat imbalanced dataset. Let's first convert the dataset into three classes: negative, neutral, and positive sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei0xmdi1Chp0"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-155O-SFSqE"
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3tY3ECJDPaz",
        "outputId": "a3804619-7b7a-4c74-b32f-46eb07375f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# TODO: Q3. Plot the histogram of review sentiments, and show that it is now approximately balanced.\n",
        "df[\"sentiment\"].hist(bins=20)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6934edcc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Let's now load a pre-trained BERT model and the corresponding tokenizer, which converts text data into tokens. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Mj-0ne--5t"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3AfJSZ8NNLF"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrSbwTQ-wi_"
      },
      "source": [
        "Let's see how tokenization works. Here is the test sentence. Convert into tokens using the `tokenizer.tokenize` and `tokenizer.convert_tokens_to_ids` methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZMitwrqm2eb"
      },
      "source": [
        "sample_txt = 'Every day feels like the same during the lock down.'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTFhpHpsoWO7",
        "outputId": "4c5eb690-bd4d-4ff4-ec7e-fb3adaf4f9d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q4. Print the tokens and token ids of the sample text above.\n",
        "print(tokenizer.tokenize(sample_txt))\n",
        "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sample_txt)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Every', 'day', 'feels', 'like', 'the', 'same', 'during', 'the', 'lock', 'down', '.']\n",
            "[4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9ap7jdL0LYU"
      },
      "source": [
        "BERT has special tokens for sentence separators \\[SEP\\] and unknown words \\[UNK\\]. This can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method, which takes the test sentence and encodes it into `input_ids`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vea9edaaxSPO",
        "outputId": "d159d278-7d77-404e-fc2e-a1c086c5abed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS69c8WvdOED"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBmcOla0yQR",
        "outputId": "9873f736-143b-49fa-ebb9-051807718a8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205,  119,\n",
              "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyVPsNdyc1"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wiv5LLiw03Ox",
        "outputId": "ea63dbb0-d4d5-4e4d-ce20-772af64cba0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RvhC4jNHHy"
      },
      "source": [
        "Use the `tokenizer.convert_ids_to_tokens` method to invert the encoded token ids (the above tensor of length 32) and visualize the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IagGoafKLUwW",
        "outputId": "0fbe56ca-6ec9-41bf-c53a-638a9d8f14d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q5. Invert the encoded token ids.\n",
        "print(tokenizer.convert_ids_to_tokens(encoding['input_ids'][0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Every', 'day', 'feels', 'like', 'the', 'same', 'during', 'the', 'lock', 'down', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6ajl30t6du"
      },
      "source": [
        "Most reviews in the dataset contain less than around 120 tokens, but let us choose a maximum length of 160."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7xSmJtLuoxW"
      },
      "source": [
        "MAX_LEN = 160"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvcoU6nurHy"
      },
      "source": [
        "# Building the dataset\n",
        "\n",
        "Let's now create a dataset using the tokenizer. Here is some code that does this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BPgRJ7YBK0"
      },
      "source": [
        "# class GPReviewDataset(Dataset):\n",
        "class GPReviewDataset():\n",
        "  \n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2uwsvCYqDJK"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data into 90-5-5 train-validation-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-vWzoo81dvO",
        "outputId": "800a082a-d67f-40fd-b139-2ac7b292c649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q6. Create three data frames: df_train, df_val, df_test as above and print their shapes.\n",
        "shuffle_df = df.sample(frac=1.0)\n",
        "\n",
        "rows, cols = shuffle_df.shape\n",
        "split_index_1 = int(rows * 0.05)\n",
        "split_index_2 = int(rows * 0.1)\n",
        "\n",
        "df_test = shuffle_df.iloc[0: split_index_1, :]\n",
        "df_val= shuffle_df.iloc[split_index_1:split_index_2, :]\n",
        "df_train = shuffle_df.iloc[split_index_2: rows, :]\n",
        "\n",
        "train_samples_size = len(df_train)\n",
        "val_samples_size = len(df_val)\n",
        "test_samples_size = len(df_test)\n",
        "\n",
        "print(\"The shape of the traning set: \",df_train.shape)\n",
        "print(\"The shape of the validation set: \",df_val.shape)\n",
        "print(\"The shape of the testing set: \",df_test.shape)\n",
        "\n",
        "print(\"The number of samples in training set: \",train_samples_size)\n",
        "print(\"The number of samples in validation set: \",val_samples_size)\n",
        "print(\"The number of samples in testing set: \",test_samples_size)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the traning set:  (14172, 12)\n",
            "The shape of the validation set:  (787, 12)\n",
            "The shape of the testing set:  (787, 12)\n",
            "The number of samples in training set:  14172\n",
            "The number of samples in validation set:  787\n",
            "The number of samples in testing set:  787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tQ1x-vqNab"
      },
      "source": [
        "We also need to create a couple of data loaders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEGqcvkuOuTX"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.content.to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vODDxMKsPHqI"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "\n",
        "# print(len(train_data_loader))\n",
        "# print(len(val_data_loader))\n",
        "# print(len(test_data_loader))\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6dlOptwqlhF"
      },
      "source": [
        "Let's have a look at an example batch from our training data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y93ldSN47FeT",
        "outputId": "e004ae33-3166-4c29-b916-ce561fc1c706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "data = next(iter(train_data_loader))\n",
        "data.keys()\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)\n",
        "print(data['targets'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16])\n",
            "tensor([0, 2, 1, 1, 2, 0, 2, 1, 1, 0, 2, 1, 0, 0, 2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440Nd31VTHER"
      },
      "source": [
        "Let's now load the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our sentiment classifier on top of it. Load the model using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P41FayISNRI"
      },
      "source": [
        "from transformers import BertModel\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFE7YSbFdY4t"
      },
      "source": [
        "And encode our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1aoFxbQSn15"
      },
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLu8zmqbaHV"
      },
      "source": [
        "The `last_hidden_state` is the sequence of hidden states of the last layer of the model. The `pooled_output` can be thought of as a summary of the content in the test sentence. Try printing out the sizes of `last_hidden_state` and `pooled_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJHXNpIbcci",
        "outputId": "436d9118-b7a3-44e0-81b0-d0640cac3fa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q7. Print the sizes of the hidden states and the pooled output.\n",
        "print(\"The sizes of the hidden states: \", last_hidden_state.shape)\n",
        "print(\"The sizes of the pooled output: \", pooled_output.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sizes of the hidden states:  torch.Size([1, 32, 768])\n",
            "The sizes of the pooled output:  torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_NiS3WgOFf"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_mRflxPl32F"
      },
      "source": [
        "import torch.nn as nn\n",
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg8m3NQJahc"
      },
      "source": [
        "Note that our sentiment classifier takes the BERT backbone and adds a dropout layer (for regularization) and a linear dense layer, which we train using cross-entropy. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0yQnuSFsjDp"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCPCFDLlKIQd"
      },
      "source": [
        "We'll move the example batch of our training data to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7p__CqdaMO"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr1EgkEtKOIB"
      },
      "source": [
        "To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rTCj46Zamry",
        "outputId": "2d2ba780-387a-432d-bc86-a9216815e4b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.nn import functional as F \n",
        "\n",
        "F.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3880, 0.2686, 0.3434],\n",
              "        [0.5506, 0.2484, 0.2010],\n",
              "        [0.3667, 0.3850, 0.2483],\n",
              "        [0.3008, 0.3867, 0.3125],\n",
              "        [0.3844, 0.2969, 0.3187],\n",
              "        [0.4768, 0.2033, 0.3198],\n",
              "        [0.4767, 0.1381, 0.3852],\n",
              "        [0.3656, 0.3089, 0.3256],\n",
              "        [0.4025, 0.2819, 0.3155],\n",
              "        [0.2053, 0.2775, 0.5172],\n",
              "        [0.4521, 0.1833, 0.3646],\n",
              "        [0.3584, 0.2365, 0.4051],\n",
              "        [0.4720, 0.2088, 0.3192],\n",
              "        [0.3665, 0.2788, 0.3547],\n",
              "        [0.3459, 0.1729, 0.4812],\n",
              "        [0.4657, 0.2086, 0.3257]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAZsOZNHD_Ux"
      },
      "source": [
        "Check the prediction and the target format so as to produce the correct predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvJ7B4_bBR9q",
        "outputId": "5118ca94-2cf2-41a0-f14e-5591be67fab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "  import numpy as np\n",
        "  targets = data[\"targets\"].to(device)\n",
        "  outputs = model(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask\n",
        "  )\n",
        "\n",
        "  _, preds = torch.max(outputs, dim=1)\n",
        "  \n",
        "  print(preds)\n",
        "  print(targets)\n",
        "  \n",
        "  correct_predictions = 0\n",
        "  correct_predictions += (preds == targets).sum()\n",
        "\n",
        "  print(correct_predictions)\n",
        "  n_examples = len(preds)\n",
        "  \n",
        "  print(\"data size:\", len(preds))\n",
        "  train_acc = correct_predictions.double() / n_examples\n",
        "  print(train_acc)\n",
        "  print(f'Train accuracy {train_acc}')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2, 2, 2, 0, 1, 0, 0, 0, 1, 0, 2, 0, 0, 1, 2, 2], device='cuda:0')\n",
            "tensor([0, 2, 1, 1, 2, 0, 2, 1, 1, 0, 2, 1, 0, 0, 2, 1], device='cuda:0')\n",
            "tensor(7, device='cuda:0')\n",
            "data size: 16\n",
            "tensor(0.4375, device='cuda:0', dtype=torch.float64)\n",
            "Train accuracy 0.4375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xikRdtRN1N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To train the model, we will use the AdamW optimizer and a linear learning-rate scheduler with no warmup steps, along with the cross-entropy loss. Five epochs (full passes through the training data should be enough) should be enough, but you can experiment with more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-ArJ2fCCcU"
      },
      "source": [
        "from transformers import AdamW\n",
        "import transformers\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "# scheduler = get_linear_schedule_with_warmup(\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8522g7JIu5J"
      },
      "source": [
        "\n",
        "Let's continue with writing a helper function for training our model for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzl9UhuNx1_Q"
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    # TODO Q8. Complete the incomplete code snippets below to finish training.\n",
        "    \n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    \n",
        "    correct_predictions += (preds == targets).sum()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PniYIte0fr"
      },
      "source": [
        "Let's write another function that helps us evaluate the model on a given data loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXeRorVGIKre"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  # TODO: Q9. Reproduce the above code but only evaluate the model (without any weight updates).input_ids = d[\"input_ids\"].to(device)\n",
        "  losses = []\n",
        "  correct_predictions = 0  \n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += (preds == targets).sum()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rdSDBHhhCh"
      },
      "source": [
        "Using those two, we can write our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhHoFNsxufs",
        "outputId": "7bd85273-5e33-4071-c030-bb7234ec3fad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "from collections import defaultdict\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  # TODO: Q10. Complete the code below to track train and test accuracy.losses\n",
        "\n",
        "  train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device, scheduler, train_samples_size)\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(model, val_data_loader, loss_fn, device, val_samples_size)\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.7797234255828922 accuracy 0.640770533446232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.6337454545497895 accuracy 0.7280813214739518\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.49418334006153164 accuracy 0.8052497883149873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.5775604197382926 accuracy 0.7928843710292249\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.2925225176814834 accuracy 0.9066469093988145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.6026012329757213 accuracy 0.8259212198221093\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.20565006219252155 accuracy 0.9424216765453006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.7144597454741597 accuracy 0.841168996188056\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.15515340510918707 accuracy 0.9588625458650861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.705768810622394 accuracy 0.8475222363405337\n",
            "\n",
            "CPU times: user 21min 29s, sys: 14min 55s, total: 36min 25s\n",
            "Wall time: 36min 40s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8-5zWsiVur"
      },
      "source": [
        "Note that we're storing the best model, indicated by the highest validation accuracy.\n",
        "\n",
        "Plot train and validation accuracy as a function of epoch count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FWG7kBm372V",
        "outputId": "5f42b706-9fcf-4860-aa13-7a4a098afdb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "# TODO: Q11. Plot train/validation accuracies.\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "train_acc_plot = history['train_acc'];\n",
        "\n",
        "val_acc_plot = history['val_acc'];\n",
        "\n",
        "plt.plot(range(EPOCHS),train_acc_plot,'-',linewidth=3,label='Training accuracy')\n",
        "plt.plot(range(EPOCHS),val_acc_plot,'-',linewidth=3,label='Validation accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6934ef72b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e+bXgkkIUhvUhVpARREieiKyqooKugqrIuoK3bdxYYs6qr7Y20rsmLDHjvLuqiLQmysSq/SDRAEAgklIT3z/v6YyaQwCROSyaS8n+fJw9xzz733zQ0z79x77jlHVBVjjDGmogB/B2CMMaZ+sgRhjDHGI0sQxhhjPLIEYYwxxiNLEMYYYzwK8ncAtSU+Pl47dep0wtsfPXqUyMjI2guollhc1WNxVY/FVT2NMa7ly5cfUNWWHleqaqP4GThwoNbE4sWLa7S9r1hc1WNxVY/FVT2NMS5gmVbyuWq3mIwxxnhkCcIYY4xHliCMMcZ41GgaqT0pLCwkLS2NvLy849aNiYnh559/roOoqsfiqp7jxRUWFka7du0IDg6uw6iMaZgadYJIS0sjOjqaTp06ISJV1s3KyiI6OrqOIvOexVU9VcWlqmRkZJCWlkbnzp3rODJjGp5GfYspLy+PuLi44yYH0zSICHFxcV5dURpjGnmCACw5mHLs/4NpTA7nFLI27TA/7S1i+/7sWt9/o77FZIwxDVlRsYM9h/PYmZlT+pNR+vpwbqG7bmzbdLq0jKrV41uC8KGMjAxGjhwJwN69ewkMDKRlS2eHxZ9++omQkJBKt122bBlvvPEGjz32WJXHGDp0KEuWLKm9oI0xdSorr5CdmTnscn3o73AlgF2ZOaQdzKXI4d2cPTszc2o9NksQPhQXF8eqVasAmD59OlFRUdxzzz3u9UVFRQQFef4TJCYmkpiYSFZWVpXHaIjJobi4mMDAQH+HYUydcDiUvUfyjrkC2OFKAplHC05432HBAXSIjSDCkUvPk5rVYtROliDq2MSJEwkLC2PlypUMGzaMcePGcfvtt5OXl0d4eDivvfYaPXr0ICUlhZkzZ/Luu+8yffp0du7cyfbt29m5cyd33HEHt912GwBRUVFkZ2eTkpLC9OnTiY+PZ926dQwcOJC33noLEWHBggXcddddREZGMmzYMLZv386nn35aLq7U1FSuvfZajh49CsDzzz/P0KFDAXjyySd56623CAgI4IILLuCJJ55g27Zt3HPPPezfv5/AwEA++OADdu3axcyZM937njJlComJiUycOJFOnTpx1VVXsXDhQv70pz+RlZXFnDlzKCgo4OSTT+bNN98kIiKCffv2cdNNN7F9+3YAZs+ezeeff05sbCx33HEHAA888AAJCQncfvvtdfI3M+Z4cgqK2JWZy46Mo+5v/ztcCSEtM5eCYscJ77tldCgdYyPoEBtB+9gIOsY5X3eIjaBldCgiQkpKCiOGdKjF38jJpwlCREYBzwKBwMuq+kSF9R2BV4GWQCbwO1VNc60rBta6qu5U1YtrEkunqf+pyeZVSn3iomrVT0tLY8mSJQQGBnLkyBG+/fZbgoKC+PLLL7n//vv56KOPjtlm48aNLF68mKysLHr06MHNN998zLP8K1euZP369bRp04Zhw4bx/fffk5iYyI033sg333xD586dGT9+vMeYEhISWLhwIWFhYWzZsoXx48ezbNkyPvvsM/71r3/x448/EhERQWZmJgCTJk3igQceYMyYMeTl5eFwONi1a1eVv3dcXBwrVqwAnLffbrjhBgAefPBBXnnlFW699VZuu+02zj77bD755BOKi4vJzs6mTZs2XHbZZdxxxx04HA6Sk5P56aefqnXOjakJVWV/Vj6bDxaTsTytfJtAZg77s/JPeN8hgQG0iw13J4EOcZHuBNA+NpyIEP99j/fZkUUkEJgFnAekAUtFZL6qbihTbSbwhqq+LiLnAI8D17rW5apqP1/F509XXHGF+xbL4cOHmTBhAlu2bEFEKCws9LjNRRddRGhoKKGhoSQkJLBv3z7atWtXrs7gwYPdZf369SM1NZWoqCi6dOnifu5//PjxzJkz55j9FxYWMmXKFFatWkVgYCCbN28G4Msvv+T3v/89ERERAMTGxpKVlcWePXsYM2YM4Ox85o2rrrrK/XrdunU8+OCDHDp0iOzsbM4//3wAFi1axBtvvAFAYGAgMTExxMTEEBcXx8qVK9m3bx/9+/cnLi7Oq2Ma4628wmLSDpbeBiq5BbQjI4ddB3PIK3RdBfy4utr7jo0McX/od4xzXgmUvG4VHUZAQP18us6XqWkwsFVVtwOISDJwCVA2QfQG7nK9XgzM82E89UbZYXkfeughkpKS+OSTT0hNTWXEiBEetwkNDXW/DgwMpKio6ITqVObpp5+mVatWrF69GofD4fWHfllBQUE4HKWX0hX7G5T9vSdOnMi8efPo27cvc+fOJSUlpcp9T5o0iblz57J3716uv/76asdmjKqScbTgmCeBSl7vPXLi/WOCAoR2LcKPuQXUITaS9rHhRIc1zJ77vkwQbYGy9xzSgCEV6qwGLsN5G2oMEC0icaqaAYSJyDKgCHhCVY9JHiIyGZgM0KpVq2M+ZGJiYtyNvGsfOKvKYGvScHq8hmSA/Px8goODKSwsJDc3171NRkaG+1v5iy++iKqSlZVFTk4ORUVFFBcXu7ct2cbhcJCdne1eLlu/pKygoIC8vDzatGnDtm3bWLduHR07duStt94qV6/E/v37adu2LUePHuWtt96iuLiYrKwshg0bxpNPPsnFF1/svsUUGxtLmzZtePfddxk9ejT5+fkUFxcTFxfH+vXrOXDgALm5uXz55ZfuhnZVJTs7253Ejhw5QnR0NJmZmbzxxhu0bt2arKwszjrrLJ5++mluueUW9y2mmJgYzj33XB588EGKiop48cUXKz3nJXFXJS8v77gJqbaVtBPVN40triKHciBXSc9xsD9X2Z/jID1H3a/zik88pshgiA1VWkcF0TI8gJYRQkJEAC3DhdgwITBAgFznjyMDDkD6AUg/8UN6zVd/R383Ut8DPC8iE4FvgN1AyZ+wo6ruFpEuwCIRWauq28purKpzgDkAiYmJWvHb988//+z1cBC+Hjqi5PZQcHAw4eHh7mPdf//9TJgwgb///e9cdNFFiAjR0dFEREQQFBREYGCge9uSbQICAoiKinIvl61fUhYSEkJYWBgJCQnMnj2bsWPHEhkZyaBBgwgODj7md73jjju4/PLLee+99xg1ahSRkZFER0dz2WWXsXnzZpKSkggJCeHCCy/kr3/9K3PmzOHuu+/m8ccfJzg4mA8++IBevXpx1VVXccYZZ9C5c2cGDBhAWFgY0dHRiEi5mB999FFGjhxJy5YtGTJkiPv8v/DCC0yePJm3336bwMBAZs+e7b5tNnLkSJo3b07z5s0rPc/e/B3DwsLo37//CfwVT1xKSkqlV4f+1NDiUlUO5xa6HwWteDWw53AuXj4VeowAgTbNw91XAO1jI+gYW9oeEBMR3ODOV02Jc76I2iciZwDTVfV81/J9AKr6eCX1o4CNqtrOw7q5wKeq+mFlx0tMTNRly5aVK/v555/p1auXV/E2xLGFvJWdnU1UVBSqyi233EK3bt248847/R5XdTgcDgYMGMAHH3xAt27dahRXdf5f1Jam9sFSE0XFDj7+IoU23U5jR2aZp4JciSArz/tbpxVFhQaV3v4pdysogrYtwgkOrHpwifp4vqBmcYnIclVN9LTOl1cQS4FuItIZ55XBOODqCoHFA5mq6gDuw/lEEyLSAshR1XxXnWHA33wYa6P20ksv8frrr1NQUED//v258cYb/R1StWzYsIHRo0czZsyYKpODabj2Hs5j8aZ0Fm1M5/utB8gpKIZvfqz2fkTgpGZhlTQIR9IiItiGW6kGnyUIVS0SkSnAFzgfc31VVdeLyAycU9zNB0YAj4uI4rzFdItr817AiyLiwDle1BMVnn4y1XDnnXfW+IrBn3r37u3uF2Eah2KHsmrXQRZtTGfxxv1s2HPE623DgwM99gnoEBdB2+bhhAVbJ8za4tM2CFVdACyoUDatzOsPgWNuG6nqEqCPL2MzxtStQzkFfL15P4s3pvP15v0czPH8SDdAsxChe+vm5W4DlVwNtIwKtauAOuLvRmpjTCOlqmzcm+W6Skhnxc6DlTYgBwUIgzvHck7PBJJ6JrBz3VKSkobWbcDmGJYgjDG1JqegiO+3ZrBoYzopm9LZc7jyvgUto0NJ6tGSc3omMOzk+HJ9BXbZFUK9YAnCGFMjOzKOsnhjOos27eeH7RkUFHked0gE+rZrTlKPBM7pmcApbZrV2x7ExskShA8lJSUxdepU9zASAM888wybNm1i9uzZHrcZMWIEM2fOJDExkQsvvJAXX3zxmMc2PY0MW9G8efPo3r07vXv3BmDatGmcddZZnHvuubXwm5mmrKDIwbLUTBZtTGfRpnS27z9aad3osCDO6t6Sc3okcHaPlsRHhVZa19Q/liB8aPz48SQnJ5dLEMnJyfztb949sbtgwQKveml7Mm/ePEaPHu1OEDNmzDih/fiTDQtef6Rn5ZGycT+LN6Xz7ZYDZOdX3hehe6soknomcE6PBAZ2bEHQcfoWmPrL/nI+NHbsWP7zn/9QUOAc7z01NZVff/2V4cOHc/PNN5OYmMgpp5zCww8/7HH7Tp06kZGRAcBjjz1G9+7dOfPMM9m0aZO7zksvvcSgQYPo27cvl19+OTk5OSxZsoT58+dz77330q9fP7Zt28bEiRP58EPnA2NfffUV/fv3p0+fPlx//fXk5+e7j/fwww8zYMAA+vTpw8aNG4+JKTU1leHDhzN8+HAGDBhQbj6KJ598kj59+tC3b1+mTp0KwNatWzn33HPp27cvAwYMYNu2baSkpDB69Gj3dlOmTGHu3LnuGP785z+7O8V5+v0A9u3bx5gxY+jbty99+/ZlyZIlTJs2jVmzZrn3+8ADD/Dss89W749mAOccBqt2HeKphZv57T++Y/BjX/Gnj9bw2bq9xySH0KAAzumZwCOXnsp3f07iv3eezX0X9GJIlzhLDg1c07mCmB5T5eoa9QmefthjcWxsLIMHD+azzz7jkksuITk5mSuvvBIR4bHHHiM2Npbi4mJGjhzJmjVrOO200zzuZ/ny5SQnJ7Nq1SqKiooYMGAAAwcOBOCyyy7zOGz2xRdfzOjRoxk7dmy5feXl5TFx4kS++uorunfvznXXXcfs2bPdcy3Ex8ezYsUKXnjhBWbOnMnLL79cbvuSYcELCwvZu3fvcYcFv+aaa5g6dWqdDQt+6aWXMnXqVBsW/AQczi3k2y37WbQxna837Sejiols2jYP55yezraEM7rGWd+DRqrpJAg/KbnNVJIgXnnlFQDef/995syZQ1FREXv27GHDhg2VJohvv/2WMWPGuIfcvvji0qkxKhs2uzKbNm2ic+fOdO/eHYAJEyYwa9Ysd4K47LLLABg4cCAff/zxMduXDAu+YsUKgoODjzss+O7du+t0WPDY2FgbFtxLqsruLAf//Hobizems2zHQYoreQ41MEBI7NjCnRROToiyvghNgCUIH7vkkku48847WbFiBTk5OQwcOJBffvmFmTNnsnTpUlq0aMHEiROPGRrbW9UdNvt4SkZbrWy48JJhwZcsWUJkZGS9Gxb8uuuus2HBq5BXWMz/tjkfQ120MZ3dh3KBY28lAsRHhXB2d2dCOLNbPDHhDXPIanPimk6CqOQ2UAlfDT4XFRVFUlIS119/vXs2tyNHjhAZGUlMTAz79u3js88+q3KgrbPOOouJEydy3333UVRUxL///W/3eEpZWVm0bt2awsJC3n77bdq2bQs4R3j11MDdo0cPUlNT2bp1q3uqz7PPPtvr3+fw4cO0a9eOgIAA3nzzTYqLnYPvnnfeecyYMYNrrrmm3LDg7dq1Y968eVx66aXuYcE7duzIhg0byM/PJzc3l6+++oozzzzT4/Eq+/1GjhzpvjVWdljw3/72tzz++OMUFhbyzjvveP17NWZpB3Ocj6FuTGfJtgzyK3kMFeC0djEk9XB2VjutbYw9htrENZ0E4Ufjx49nzJgxJCcnA9C3b1/69+9Pz549ad++PcOGDaty+wEDBnDVVVfRt29fEhISGDRokHvdI488wpAhQ8oNmw0wbtw4brjhBp577jl34zQ4b/O89tprXHHFFRQVFTFo0CBuuukmr3+XP/7xj1x++eXMnTuXCy+80P1tf9SoUaxatYrExMRyw4K/+eab3HjjjUybNs09LHiXLl248sorOfXUU+ncuXOVQ29X9vs9++yzTJ48mVdeecU9LPgZZ5xBSEgISUlJNG/evMk+AVVY7GD5joMs3uTswbx5X3aldcMCIanXSST1TGBEj5YkRFf/itA0Xj4b7ruu2XDfdau+xnX48GHOPvvsKocFb4zDfR/IzufrTftZtCmdbzbvr3JI7K4tI91DWuTsWMu55yT5LK4T1RiH1falhjjctzF1asOGDVx00UVcdtlljX5YcIdDWf/rEXdntTVph6jsu15IUABndIlzDWvRig5xEe51KbvsFpKpnCUI02j07t2bNWvW1Msrm9qQlVfId1sOOMc52ryf/Vn5ldZtHRPm7qw29OQ4IkLsrW6qr9H/r1FVexzPuDWkW6qqyvYDR90NzEtTMyks9hx/gMDAji2cSaFnAj1aRdv/e1NjjTpBhIWFkZGRQVxcnL1ZDKpKRkbGCT2aW1fyCov58ZdMd1LYmZlTad0WEcGMcD1xdFa3eJpHhNRhpKYpaNQJol27dqSlpbF///7j1s3Ly6uXHxwWV/UcL66wsDDatTtm2nO/2nM41z2z2vdbD5BbWFxp3d6tm7kbmPu1b06gPYZqfKhRJ4jg4GA6d+7sVd2UlJQqH7f0F4ureuprXGUVFTtYteuQu7Paxr2VD8gYERLImSfHc07PBEb0SOCkmPqXlE3j1agThDH1RXaBMm/lbhZtTOebLfs5VMV0m53jI91zJgzq3ILQoKbZn8P4nyUIY3xow69H+Mu/1/PTLzkoqzzWCQkMYEiXWEa4kkLn+EiP9Yypa5YgjPGRz9ft4c73VntsU2jVLNQ9pMWZJ8cTGWpvRVP/2P9KY2qZqvKPRVt5auFmd5kA/Ts0dzcw927dzJ6sM/WeTxOEiIwCngUCgZdV9YkK6zsCrwItgUzgd6qa5lo3AXjQVfVRVX3dl7EaUxtyC4q598PVfLpmj7usY1wEk3sp14yueswtY+obn033JCKBwCzgAqA3MF5EeleoNhN4Q1VPA2YAj7u2jQUeBoYAg4GHRaSFr2I1pjbsPZzHlS/+r1xyGNo1jnl/HEbbKJtZzTQ8vvxfOxjYqqrbVbUASAYuqVCnN7DI9XpxmfXnAwtVNVNVDwILgVE+jNWYGlm16xAXP/8da3eXDiv/u9M78Pr1g2kRaR3YTMPks9FcRWQsMEpVJ7mWrwWGqOqUMnXeAX5U1WdF5DLgIyAe+D0QpqqPuuo9BOSq6swKx5gMTAZo1arVwJLhtE9EdnY2UVFRJ7y9r1hc1eOPuH74tYhX1uVT6JpmIUDgml4hjOxQOsGOna/qsbiqpyZxJSUl1dvRXO8BnheRicA3wG6g8m6kFajqHGAOOIf7rskwvI1xGF9fsricI6o+tXAz/1yz1V0WEx7M7GsGMPTkeL/FVR0WV/U0tbh8mSB2A+3LLLdzlbmp6q/AZQAiEgVcrqqHRGQ3MKLCtik+jNWYajmaX8Sd763ivxv2ucu6tozklQmD6GT9GEwj4cs2iKVANxHpLCIhwDhgftkKIhIvIiUx3IfziSaAL4DfiEgLV+P0b1xlxvhd2sEcLp+9pFxyOLt7Sz65ZZglB9Oo+OwKQlWLRGQKzg/2QOBVVV0vIjOAZao6H+dVwuMiojhvMd3i2jZTRB7BmWQAZqhqpq9iNcZbS1MzuenN5WQcLXCXTTqzM/dd2MsGzjONjk/bIFR1AbCgQtm0Mq8/BD6suJ1r3auUXlEY43fvL9vFA5+sdc/JEBwoPHZpH64c1P44WxrTMPm7kdqYeq/YoTy+4Gde/u4Xd1lsZAgvXjuQQZ1i/RiZMb5lCcKYKhzJK+S2d1eSsql0TpGeJ0Xz0nWJtI+NqGJLYxo+SxDGVCL1wFEmvbGMrenZ7rLzerfimav62eB6pkmw/+XGeLBk2wH++PaKcvM23JLUlbvP60GANUabJsIShDEVvPnDDv4yfz1FDmdjdEhQAP839jQu6dfWz5EZU7csQRjjUljsYMa/N/DmDzvcZS2jQ3npukT6tW/ux8iM8Q9LEMYAh3IK+OPbK1iyLcNd1qdtDHOuG0jrmHA/RmaM/1iCME3e1vQsJr2+jNSMHHfZRae1ZubYvoSH2HzQpumyBGGatJRN6dz6zkqy8ovcZXed151bzznZZnwzTZ4lCNMkqSqvfp/KY//ZgKstmvDgQJ66si8X9Gnt3+CMqScsQZgmp6DIwUPz1vHesl3usjYxYcy5LpFT28b4MTJj6hdLEKZJOZCdz81vLWdp6kF3Wf8OzXnx2oEkRIf5MTJj6h9LEKbJ+HnPESa9vozdh3LdZZcNaMtfx/QhLNgao42pyBKEaRL+u34vd7y3ipwC54SFIjB1VE8mn9XFGqONqYQlCNOoqSovpGxj5n83UTL9emRIIM+N78/IXq38G5wx9ZwlCNNo5RUWM/WjNcxb9au7rH1sOK9MGET3VtF+jMyYhsEShGmU0o/kccOby1m965C7bEjnWGb/biCxkSF+jMyYhsMShGl01qYd5oY3lrH3SJ67bPzg9vzl4lMJCfLlNOzGNC6WIEyj8tOeIl79agl5hQ4AAgSmje7NhKGdrDHamGqyBGEaBYdDeearLbywOt9dFh0WxKyrB3BW95Z+jMyYhssShGnwcgqKuPv91Xy2bq+7rEt8JC9NSKRryyg/RmZMw2YJwjRovx7KZdLry9iw54i7bHi3eJ4fP4CYiGA/RmZMw+fTFjsRGSUim0Rkq4hM9bC+g4gsFpGVIrJGRC50lXcSkVwRWeX6+acv4zQN0/IdB7n4+e/LJYfzOgbx2sRBlhyMqQU+u4IQkUBgFnAekAYsFZH5qrqhTLUHgfdVdbaI9AYWAJ1c67apaj9fxWcato9XpDH1o7UUFDsbo4MChBmXnEqb3O0EBdqTSsbUBl++kwYDW1V1u6oWAMnAJRXqKNDM9ToG+BVjqlDsUB7/7Gfuen+1Ozm0iAjmrUlDuHpIBz9HZ0wdU4WCo4TkH4TcQ8evX02iJeMP1PaORcYCo1R1kmv5WmCIqk4pU6c18F+gBRAJnKuqy0WkE7Ae2AwcAR5U1W89HGMyMBmgVatWA5OTk0843uzsbKKi6l+DpsVVKrdI+efqfFbvL3aXtY0Sbh8QRkJEgN/i8obFVT2NOi4tJrA4j6CiXAKLnT9BRTllXpeWH7uu7Os8AotzEZxflH7pdA07Ol1Z7XCSkpKWq2qip3X+bqQeD8xV1b+LyBnAmyJyKrAH6KCqGSIyEJgnIqeo6pGyG6vqHGAOQGJioo4YMeKEA0lJSaEm2/uKxeW0MyOHSW8sZXOZ5DCyZwLPjOtHdFhpe4Odr+qxuLxUXAj5Wfzw9UJO79UZ8rOhIAvys1yvs12vs1yvs8u8rlBeeNQnIXZuE0fnWj5nvkwQu4H2ZZbbucrK+gMwCkBV/yciYUC8qqYD+a7y5SKyDegOLPNhvKae+mF7Bje/tZyDOYXushvP7sKfzu9JYIB1fjMeqEJRXjU+yCuur7BdsbN/zekAP/r1NztWUBgFEkpIUGjt77rW91hqKdBNRDrjTAzjgKsr1NkJjATmikgvIAzYLyItgUxVLRaRLkA3YLsPYzX11Ls/7eSheesocs0LGhIYwOOX9eHyge38HJnxCVXIySQ8Jw12ryj/QV7db+xafPzj+UtIlPMnNApCo12vy/wbGgUh0WVel9Rtdux2gcEs8dEVl88ShKoWicgU4AsgEHhVVdeLyAxgmarOB+4GXhKRO3E2WE9UVRWRs4AZIlIIOICbVDXTV7Ga+qeo2MGj//mZuUtS3WXxUaG8eO1ABnZs4b/ATM2oQk4GHNoBh3bBoZ3H/hQeZQjAT/4OtgwJgJBo8ggmrFl8hQ/p6Op90IdEQUDDeNLOp20QqroA56OrZcumlXm9ARjmYbuPgI98GZupvw7nFDLl3RV8u+WAu6x362a8NCGRts3D/RiZOS5VOHoADnv44HcngJy6iSUguPSDuew3b/eHt6cP8ko+6IPDQYQf6lvbiI/5u5HamHK2789m0uvL2H6gtCHvglNP4u9X9iUixP67+l1JAji003UV4CEBFOUefz9VCYkiNyCK8OYJFT7IK3xjP94HvQ/uyTc19o4z9ca3W/Zzy9srOJJX5C67bWQ37hjZjQBrjK4bqnB0fxUJYFctJIBoaN6h8p/wFvz49ddN6pt6fWUJwvidqvL6klQe+c/PFLsao0ODAph5RV9+27eNn6NrZFQhO92dADrsSIF/zytNAId3OZ/+qYmQaGjR0fOHf0x7CG/hnBTc1HuWIIxfFRQ5eHj+et79aae7rFWzUF66LpHT2jX3Y2QNlMMBR9PLfOOvcBVwOK1cAugC8Es1jxEaU8UVQHsIa24JoJGwBGH8JvNoATe/tZwffyl9QK1v++bMuXYgrZqF+TGyeszhgOx9nhPA4V3OW0DF+cffT1XCShKAh6uAmPYQbom7qfAqQYjIx8ArwGeq6vBtSKYp2Lwviz+8vpRdmaX3sy/t14YnLj+NsOBAP0bmZw4HZO/1kAB2lSaB4oKaHSOsufsDf1d2AO1PHVbhCiCmdn4X0+B5ewXxAvB74DkR+QB4TVU3+S4s05h99fM+bk9eRXZ+aWP0vef34I8jujb+aUEdxZC1t0LD7w7Xt3/XLaCaJoDwFmU+8DseewUQ1sxddVtKCu1PH1Gz45lGy6sEoapfAl+KSAzO8ZO+FJFdwEvAW6paWOUOjMHZGD3nm+088flGSsaIjAgJ5Jmr+vGbU07yb3C+kJMJ21Mg9Vv6bl0Gq7OcCcBRw7dLeGyFWz8dy18BhEbXStDA/LUAACAASURBVPjGeN0GISJxwO+Aa4GVwNvAmcAEYIQvgjONR15hMfd/spaPV5QOx9W2eTgvT0ikV+tmVWzZgBTlw64fYdsi2LYY9qzGOUCAc7hir0XEVZ4AYto7n/E3pg542wbxCdADeBP4raruca16T0RsAD1TpfSsPG56czkrdpaOVz+oUwtm/24g8VENuDOTKqRvcCaD7YthxxLveglHtnR+0HtMAu0hJNL3sRvjBW+vIJ5T1cWeVlQ2jrgxAOt2H2byG8v49XDpo5VXDGzHo2NOJTSoATZGH9njvG20fbHz3+x9ldeVQGg7ELomsSYzhNPO+i3EtLMEYBoMbxNEbxFZqaqHAESkBTBeVV/wXWimofts7R7uen81uYXOUTUDBO6/sBd/OLNzw2mMLjgKqd87E8K2xbD/56rrx3aFrknQJQk6D3c/EZSZkgIte/g+XmNqkbcJ4gZVnVWyoKoHReQGnE83GVOOqvKPRVt5auFmd1l0aBD/uLo/I3ok+DEyLziKYc8q122jFNj5Q9WNyuEtoPPZpUmhRcc6C9UYX/M2QQSKiKhrflIRCQRCfBeWaahyC4q598PVfLpmj7usU1wEL09I5OSEevp0zcHU0naE7V9DXhVz+waGQPshpQmhdV8IaIC3yozxgrcJ4nOcDdIvupZvdJUZ47b3cB43vLGMtbsPu8uGdo3jhWsG0DyiHn2fyD0Ev3xTetvo4HHGmkg4pTQhdDzD2hBMk+FtgvgzzqRws2t5IfCyTyIyDdKqXYeY/MYy0rNKh3m49vSOTPttb4ID/Tw5SlEBpC0tTQi/roCqBgSIOgm6jICu5zj/jW5VN3EaU89421HOAcx2/RhTzr9W7ebeD9dQUOT80A0MEKb/tjfXntHJPwGpwoHNpbeNUr9zTkVZmeAI6Dis9CohoZcNNmcM3veD6AY8DvTGOW80AKraxUdxmQbA4VD+vnATsxZvc5fFhAcz+5oBDD05vm6Dyd4P21PosfEdWH4zZP1aRWWBNv1LE0L7wTa5jDEeeHuL6TXgYeBpIAnnuEwNY1JV4xN5RcqNby1n4YbSfgBdW0byyoRBdIqvg3v0hbnOjmnbF8O2FNi3FoDWldVv3sF1yygJOp8FEbG+j9GYBs7bBBGuql+5nmTaAUwXkeXAtONtaBqftIM5PPZjHruySnsNj+jRkufG96dZWLBvDupwwN41pe0IO3+oeljr0BhnP4SSq4TYLnbbyJhq8jZB5ItIALBFRKYAuwEbEKYJWpN2iN+/tpSMo6WNvDcM78zUC3oRWNvTgh5OK/P4aQrkZFReNyAI2g3ml4BOdB55vfMWUqBNd2JMTXj7DrodiABuAx7BeZtpgq+CMvVT5tECJr+xnIyjzuGogwOFx8b04crE9rVzgLwjzgblkquEjC1V14/vUXqF0GkYhEazIyWFzu0H1U48xjRxx00Qrk5xV6nqPUA2zvYHr4jIKOBZIBB4WVWfqLC+A/A60NxVZ6qqLnCtuw/4A1AM3KaqX3h7XFP7HA7lng9Ws/eIc0ylyGCY+4fTGdSpBvfyi4tg9/LShLB7GTiKKq8fEe96/NSVFGLanvixjTHHddwEoarFInJmdXfsSiyzgPOANGCpiMxX1Q1lqj0IvK+qs0WkN7AA6OR6PQ44BWiDc/6J7qpaXN04TO14+bvtLNqY7l6+oU9o9ZODKmRuLx0OO/VbyD9Sef2gMOhwRmlCaHUqBNizEcbUFW9vMa0UkfnAB8DRkkJV/biKbQYDW1V1O4CIJAOXAGUThAIlkwHEACXPJl4CJKtqPvCLiGx17e9/XsZratGKnQf52+elEwjeMLwz/SLTq9iijJJJc0qeNjq8s+r6J51WmhA6nAHBNje1Mf4iWjK1V1WVRF7zUKyqen0V24wFRqnqJNfytcAQVZ1Spk5r4L8451OJBM5V1eUi8jzwg6q+5apXMh/2hxWOMRmYDNCqVauBycnJx/1dKpOdnU1UVP1rd/d3XEcLlWnf55KR5/x/0iUmgPuHhJGXc9RjXOIoJObwz7Q4uIrYzFVEZW9HqPz/WF5oHAdb9Odgi74cbNGXwpCazYfs7/NVGYureiyu6qlJXElJScsrm7bB257UXrc7VNN4YK6q/l1EzgDeFJFTvd1YVecAcwASExN1xIgRJxxISkoKNdneV/wZl6py45vLychzPs7aLCyI128cTvvYiNK43JPmuG4b7VgCRbmV7zQkCjqVPn4aFt+N1iKV91+oJvs7Vo/FVT1NLS5ve1K/Bsd+DazqCgLno7BlH29p5yor6w/AKNe+/iciYUC8l9saH5u7JJX/lukI97exfWkfGwFZe2m1dxF8/E61Js2hSxK0S4RAH/WVMMbUKm/bID4t8zoMGENpe0FllgLdRKQzzg/3ccDVFersBEYCc0Wkl2vf+4H5wDsi8hTORupuwE9exmpqwZq0Q/x1QenkOBOHdmJUmxz4aBKs/ZBeVdw2qmzSHGNMw+LtLaaPyi6LyLvAd8fZpsjVqe4LnI+wvqqq60VkBrBMVecDdwMvicidOK9QJrrmnFgvIu/jbNAuAm6xJ5jqzpG8Qqa8s5LCYmcSOKt1MQ/Jy/D8G54fQ7VJc4xplE60q2k34LhTg7n6NCyoUDatzOsNwLBKtn0MeOwE4zMnSFW576O17MzMoRnZ3Ba6gOuzPidgeV65eodiTqF54uU2aY4xjZi3bRBZlG+D2ItzjgjTyLz9406+WpvKzYFfcFPQfGIkx3kNV6LjMDh3Oqu25TBi+Ag/RWmMqQve3mKqp3NFmtq0Ydd+tv7nGb4J/ZgEqTDt5kmnwciH4eSRzkHvtqX4JUZjTN3x9gpiDLBIVQ+7lpsDI1R1ni+DM3XE4SBv5Xs0/3Q60wP3ll8X2xXOeQB6j7FezMY0Md62QTysqp+ULKjqIRF5GLAE0ZCpwpb/ol/9hbB962lTZlVR5EkEnXMf9LvGHks1ponyNkF4+upoYyk3ZDuWwJd/gV0/UHaQ7kMaSdopN3HqmHshONxv4Rlj/M/bD/llrj4Js1zLtwDLfROS8ak9a2DRI7Dlv+WKczSUV4ovYH+fG5hxZbXHZjTGNELeJohbgYeA93A+zbQQZ5IwDUXGNlj8V1hXbjgrCgniraKRzCq6lBYJbZk/5gw/BWiMqW+8fYrpKDDVx7EYXziyB775G6yo2MlNWBbzG+5Iv4A0TSAsOIB3rhlAeIj1ZzDGOHn7FNNC4ApVPeRaboFzOO7zfRmcqYHcg/DdM/Dji8cOntfjIr5sfQOTPi+dU3rGJafSvZU9zWyMKeXtLab4kuQAoKoHReS4PamNHxQchR//Cd89C/mHy6/reCac+zBbQ3tz2/OlI6WM6d+WKwa2q+NAjTH1nbcJwiEiHVR1J4CIdMLD6K7Gj4oKYMXr8PXf4GiFyXxOOg3OfRi6jiSvyMGUWd+TU+Ac2qpLfCSPXnoqIuJhp8aYpszbBPEA8J2IfA0IMBzXRD3GzxwOZ8Pz4sfgYGr5dbFd4ZwHofel7k5uf/n3BjbuzQIgJCiA568eQGSoPbFsjDmWt43Un4tIIs6ksBJnB7kqZoUxPqcKm7+Ar2ZA+vry66LbwIg/H9PJbf7qX3n3p9IpPx/+bW96t2mGMcZ44m0j9STgdpwT96wCTsc5P/Q5vgvNVGrHEvhyOuz6sXx5eAs48y4YfMMxndxSDxzl/o/XupdHn9aaqwd3qINgjTENlbf3Fm4HBuGcJzpJRHoCf/VdWMajPWucVwxbF5YvD46EM/4IQ2/1ODlPflExt7yzgux852OuHeMiePyyPtbuYIypkrcJIk9V80QEEQlV1Y0i0sOnkZlSGducbQzrPipfHhAMidfDWfdAVOUPlf31Pz+z/tcjAIQEBjDr6gFEh9n4SsaYqnmbINJcI7jOAxaKyEFgh+/CMgAc2UP3TS/AN18d08mNvuNgxH3Hnb3t83V7eP1/pX+q+y/syaltbQpQY8zxedtIPcb1crqILAZigM99FlVTl5MJ3zs7ubUpKj+TGz0ucj6Z1Kr3cXezKzOHez9c414+/5RWTBjaqZaDNcY0VtV+vlFVv/ZFIAZnJ7cfZsP3zx3bya3TcOeEPe0HeberIgdT3llBVp7zyqNdi3D+dnlfa3cwxnjNHoCvD6ro5JYV1ZXoS/8Pup7jnMnNS3/7fCOr05xJJihA+Mf4/sREWLuDMcZ7liD8yVEMa12d3A5VaNKJOxnOeZDl6TGMOLl6TxN/uWEfL3/3i3t56gU96d+hRW1EbIxpQixB+IMqbP4cvnqkkk5uU12d3IJgf0q1dr37UC53f7DavTyyZwJ/OLNzLQRtjGlqfJogRGQU8CwQCLysqk9UWP80kORajAASVLW5a10xUNKza6eqXuzLWOtM6vfw1V88d3IbfjcMmnTCM7kVFju47d2VHM4tBKB1TBgzr7B2B2PMifFZghCRQJwz0J0HpAFLRWS+qm4oqaOqd5apfyvQv8wuclW1n6/iq3N7Vrs6uX1Zvjw4Es64BYZO8djJrTqeWriZ5TsOAhDoandoERlSo30aY5ouX15BDAa2qup2ABFJBi4BNlRSfzzwsA/j8Y+MbbDoUVj/cfnygGAY9AcYfg9EtazxYVI2pTM7ZZt7+e7fdCexU2yN92uMabpE1TejdovIWGCUqk5yLV8LDFHVKR7qdgR+ANqparGrrAjnuE9FwBOqOs/DdpNxjSrbqlWrgcnJySccb3Z2NlFRUSe8fUUh+Rl0Sn2P1nsWIjjc5UoA+1qNILXTOPLCW9VKXAfzHEz7Ppcs550lTo0P5K6BoQT48NZSbZ+v2mJxVY/FVT2NMa6kpKTlqproaV19aaQeB3xYkhxcOqrqbhHpAiwSkbWquq3sRqo6B5gDkJiYqCNGjDjhAFJSUqjJ9m45mfDd07B0DlTs5NZzNHLOg5yU0IuTaimuomIHV7/8I1mFzsF1E6JDmXvTcOKjQk8s/lqKy18sruqxuKqnqcXlywSxG2hfZrmdq8yTccAtZQtUdbfr3+0ikoKzfWLbsZvWEwVH4YcX4Pt/1LiTW3U899UWfvolE4AAgefG9/d5cjDGNA2+TBBLgW4i0hlnYhgHXF2xkmtk2BY4hw8vKWsB5KhqvojEA8OAv/kw1hNXVADL58I3/3fsTG6t+8HIadXu5Oat77ce4B+Lt7qXbx/ZndO7xNX6cYwxTZPPEoSqFonIFOALnI+5vqqq60VkBrBMVee7qo4DkrV8Y0gv4EURcQABONsgKmvc9g9HMaz9ABb/tZJObg9B70t8khgA0rPyuD15FSVnbWjXOKacc7JPjmWMaZp82gahqguABRXKplVYnu5huyVAH1/GdsJUYdNnsOgRSK+Qs5q1dXZy63u1s5ObjxQ7lDvfW8WB7HwA4qNCeGZcPwIDrL+DMab21JdG6oYh9Tv48i+Q9lP58vDYMp3cwnwexguLt/L91gzAeYHyzFX9SYj2/XGNMU2LJQhvVNXJbegUOGMKhNXN3M4/bM/g6S83u5enJJ3Mmd3i6+TYxpimxRJEVSrr5BYYAol/cF411EInN6/Dyc7n9uSVOFztDoM7xXL7yG51dnxjTNNiCcKTI7/C10/CijehbNcMCYC+453tDM071GlIDody1/ur2XfE2e7QIiKY58b3JygwoE7jMMY0HZYgyirp5PaT505unPMQJPT0S2hzvt3O15v3u5efuqofJ8VYu4MxxncsQQDkZ9Mx9X3437WQf6T8uk7D4dzp0M5jT/Q6sXxHJv/3xSb38o1ndyGpR4Lf4jHGNA1NO0G4O7n9jc5H95df17ofnPswdEnyWV8Gb2QXKPe/s5JiV8PDgA7Nuec3PfwWjzGm6WjaCeJIGnxxHziKSsviusHIh6DXxX5NDACqystr8/n1sLMdJCY8mH9cPYBga3cwxtSBpv1JE9sFBlwHQF5oHFz8D/jjDz7tAV0dr3z3C6v2lzaSz7yiL22bn9hkQsYYU11N+woC4Kw/QWxXfsrtzlkDfuPvaNxW7TrEk59vdC9fP6wz5/U+/vDgxhhTW5r2FQRAs9YwdAqOwPoz89rh3EKmvLOCwmJnu8Np7WKYeoF/np4yxjRdliDqGVVl6kdrSDvonN8hPAieHz+AkCD7Uxlj6pZ96tQzb/6wg8/W7XUvX39qKB3iIvwYkTGmqbIEUY+s232YRz/92b187ekdGXSSNRMZY/zDEkQ9kZXnbHcoKHbOX927dTMeuKiXn6MyxjRlliDqAVXl/k/WkZqRA0BkSCCzrhlAWHCgnyMzxjRlliDqgeSlu/j36l/dy3+9rA+d4yP9GJExxliC8Luf9xxh+vz17uXxg9tzSb+2fozIGGOcLEH40dH8Iqa8s4L8Ime7Q49W0UwbfYqfozLGGCdLEH700L/WsW3/UQDCgwOZdU1/wkOs3cEYUz9YgvCTD5bt4uMVu93Lj1x6KicnRPsxImOMKc8ShB9s2ZfFtH+VtjtcPqAdYwe282NExhhzLJ8mCBEZJSKbRGSriEz1sP5pEVnl+tksIofKrJsgIltcPxN8GWddyi0o5pZ3VpBb6ByltWvLSB651NodjDH1j8+66YpIIDALOA9IA5aKyHxV3VBSR1XvLFP/VqC/63Us8DCQCCiw3LXtQV/FW1f+8u/1bN6XDUBoUACzrhlARIj1ljbG1D++vIIYDGxV1e2qWgAkA5dUUX888K7r9fnAQlXNdCWFhcAoH8ZaJ/61ajfJS3e5l/9y8Sn0PKmZHyMyxpjKiar6ZsciY4FRqjrJtXwtMERVp3io2xH4AWinqsUicg8QpqqPutY/BOSq6swK200GJgO0atVqYHJy8gnHm52dTVRU1Alvfzx7jzqYviSXPNf8P6e3DuTG00KR40xM5Ou4TpTFVT0WV/VYXNVTk7iSkpKWq2qip3X15d7GOOBDVS0+bs0yVHUOMAcgMTFRR4wYccIBpKSkUJPtq5JXWMyYF5aQV+wcwrtTXAQv3zScqNDjn35fxlUTFlf1WFzVY3FVj6/i8uUtpt1A+zLL7Vxlnoyj9PZSdbet9x79zwZ+3nMEgJDAAJ6/eoBXycEYY/zJlwliKdBNRDqLSAjOJDC/YiUR6Qm0AP5XpvgL4Dci0kJEWgC/cZU1OP9Zs4e3ftjpXn5odC9ObRvjx4iMMcY7Pvsaq6pFIjIF5wd7IPCqqq4XkRnAMlUtSRbjgGQt0xiiqpki8gjOJAMwQ1UzfRWrr+zIOMrUj9a4ly/scxK/O72jHyMyxhjv+fQ+h6ouABZUKJtWYXl6Jdu+Crzqs+B8LL+omCnvrCQrvwiA9rHhPHH5acdtlDbGmPrCelL7yBOfbWTt7sMABAcKz48fQLOwYD9HZYwx3rME4QNfrN/La9+nupenXtCLvu2b+y8gY4w5AZYgalnawRzu/WC1e/ncXq24flgn/wVkjDEnyBJELSosdnDruys5kudsd2jbPJyZV1i7gzGmYbIEUYtmfrGJlTud4w0GBQjPje9P84gQP0dljDEnxhJELVm0cR8vfrPdvXzv+T0Y2LGFHyMyxpiasQRRC/YczuXu90vbHUb0aMkNw7v4MSJjjKk5SxA1VFTs4LZ3V3IwpxCAVs1CeerKfgQEWLuDMaZhswRRQ898uYWlqc5pKgIEnhvXn9hIa3cwxjR8liBq4Nst+5mVstW9fNd53RnSJc6PERljTO2xBHGC0o/kcUfyKkpGkDrz5HhuHnGyf4MyxphaZAniBBQ7lNuTV5FxtACAltGhPH1VPwKt3cEY04hYgjgB/1i0hf9tzwBABJ69qh8to0P9HJUxxtQuSxDVtGTbAZ79aot7+dZzujH05Hg/RmSMMb5hCaIaDmTnl2t3OL1LLLeP7ObfoIwxxkcsQXjJ4VDufG8V6Vn5AMRFhvDsuP7W7mCMabQsQXhp9tfb+HbLAffyU1f1o1WzMD9GZIwxvmUJwgtLUzN5auFm9/LNI7pydveWfozIGGN8zxLEcWQeLeDWd1ZS7HA2PCR2bMHd53X3c1TGGON7liCq4HAo93ywmr1H8gBoHhHMc+P7ExRop80Y0/jZJ10VXvnuFxZtTHcv//2KvrRpHu7HiIwxpu5YgqjEip0HefLzje7lG4Z3ZmSvVn6MyBhj6pZPE4SIjBKRTSKyVUSmVlLnShHZICLrReSdMuXFIrLK9TPfl3FWdDinkFvfWUmRq92hb/vm3Ht+z7oMwRhj/C7IVzsWkUBgFnAekAYsFZH5qrqhTJ1uwH3AMFU9KCIJZXaRq6r9fBVfZVSVez9cze5DuQBEhwXx/Pj+hATZxZYxpmnx5afeYGCrqm5X1QIgGbikQp0bgFmqehBAVdPxs7lLUvnvhn3u5f8b25f2sRF+jMgYY/xDtGTciNreschYYJSqTnItXwsMUdUpZerMAzYDw4BAYLqqfu5aVwSsAoqAJ1R1nodjTAYmA7Rq1WpgcnLyCcebnZ3N/uJwHv0hj2LXKTm3QxC/6+3fQfiys7OJioryawyeWFzVY3FVj8VVPTWJKykpabmqJnpa57NbTF4KAroBI4B2wDci0kdVDwEdVXW3iHQBFonIWlXdVnZjVZ0DzAFITEzUESNGnHAgCxYu5rWVuJPDqW2bMWvyUEKDAk94n7UhJSWFmvxevmJxVY/FVT0WV/X4Ki5f3mLaDbQvs9zOVVZWGjBfVQtV9RecVxPdAFR1t+vf7UAK0N9Xgaoqc9fnszMzB4Co0CCeHz/A78nBGGP8yZcJYinQTUQ6i0gIMA6o+DTSPJxXD4hIPNAd2C4iLUQktEz5MGADPvL2jzv5aW+xe/mJy/vQKT7SV4czxpgGwWe3mFS1SESmAF/gbF94VVXXi8gMYJmqznet+42IbACKgXtVNUNEhgIviogDZxJ7ouzTT7Vpw69HmPFp6a6vHtKB0ae18cWhjDGmQfFpG4SqLgAWVCibVua1Ane5fsrWWQL08WVsANn5RUx5ZwUFRQ4Aep4UzbTRvX19WGOMaRCa9MP96UfyKHY9xRUaCLOuGUBYsLU7GGMMNPEE0aVlFP++9UwuOq01E04JpWvL+vf4mjHG+EuTThAAzcKCeX58f4a28fcTv8YYU780+QQBIGLThhpjTEWWIIwxxnhkCcIYY4xHliCMMcZ4ZAnCGGOMR5YgjDHGeGQJwhhjjEc+mw+ironIfmBHDXYRDxyopXBqk8VVPRZX9Vhc1dMY4+qoqi09rWg0CaKmRGRZZZNm+JPFVT0WV/VYXNXT1OKyW0zGGGM8sgRhjDHGI0sQpeb4O4BKWFzVY3FVj8VVPU0qLmuDMMYY45FdQRhjjPHIEoQxxhiPmlSCEJFRIrJJRLaKyFQP60NF5D3X+h9FpFM9iWuiiOwXkVWun0l1FNerIpIuIusqWS8i8pwr7jUiMqCexDVCRA6XOV/TPNXzQVztRWSxiGwQkfUicruHOnV+zryMq87PmYiEichPIrLaFddfPNSp8/ekl3H55T3pOnagiKwUkU89rKvd86WqTeIHCAS2AV2AEGA10LtCnT8C/3S9Hge8V0/imgg874dzdhYwAFhXyfoLgc8AAU4HfqwncY0APvXD+WoNDHC9jgY2e/hb1vk58zKuOj9nrnMQ5XodDPwInF6hjj/ek97E5Zf3pOvYdwHvePp71fb5akpXEIOBraq6XVULgGTgkgp1LgFed73+EBgpvp9NyJu4/EJVvwEyq6hyCfCGOv0ANBeR1vUgLr9Q1T2qusL1Ogv4GWhboVqdnzMv46pzrnOQ7VoMdv1UfGqmzt+TXsblFyLSDrgIeLmSKrV6vppSgmgL7CqznMaxbxJ3HVUtAg4DcfUgLoDLXbckPhSR9j6OyVvexu4PZ7huEXwmIqfU9cFdl/b9cX77LMuv56yKuMAP58x1u2QVkA4sVNVKz1cdvie9iQv88558BvgT4Khkfa2er6aUIBqyfwOdVPU0YCGl3xCMZytwji/TF/gHMK8uDy4iUcBHwB2qeqQuj12V48Tll3OmqsWq2g9oBwwWkVPr4rjH40Vcdf6eFJHRQLqqLvf1sUo0pQSxGyib5du5yjzWEZEgIAbI8HdcqpqhqvmuxZeBgT6OyVvenNM6p6pHSm4RqOoCIFhE4uvi2CISjPND+G1V/dhDFb+cs+PF5c9z5jrmIWAxMKrCKn+8J48bl5/ek8OAi0UkFeet6HNE5K0KdWr1fDWlBLEU6CYinUUkBGcDzvwKdeYDE1yvxwKL1NXa48+4KtyjvhjnPeT6YD5wnevJnNOBw6q6x99BichJJfddRWQwzv/nPv9QcR3zFeBnVX2qkmp1fs68icsf50xEWopIc9frcOA8YGOFanX+nvQmLn+8J1X1PlVtp6qdcH5OLFLV31WoVqvnK+hEN2xoVLVIRKYAX+B8cuhVVV0vIjOAZao6H+eb6E0R2YqzEXRcPYnrNhG5GChyxTXR13EBiMi7OJ9uiReRNOBhnA12qOo/gQU4n8rZCuQAv68ncY0FbhaRIiAXGFcHiR6c3/CuBda67l8D3A90KBObP86ZN3H545y1Bl4XkUCcCel9Vf3U3+9JL+Pyy3vSE1+eLxtqwxhjjEdN6RaTMcaYarAEYYwxxiNLEMYYYzyyBGGMMcYjSxDGGGM8sgRhTD0gztFUjxmd0xh/sgRhjDHGI0sQxlSDiPzONVfAKhF50TWoW7aIPO2aO+ArEWnpqttPRH5wDej2iYi0cJWfLCJfugbGWyEiXV27j3IN/LZRRN6ug5GEjamSJQhjvCQivYCrgGGugdyKgWuASJw9WU8BvsbZsxvgDeDPrgHd1pYpfxuY5RoYbyhQMtRGf+AOoDfO+UGG+fyXMqYKTWaoDWNqwUicg7ItdX25D8c5HLQDeM9V5y3gYxGJAZqr6teu8teBD0QkGmirqp8AqGoegGt/P6lqmmt5FdAJ+M73v5YxnlmCMMZ7AryuqveVKxR5qEK9Ex2/Eooy3AAAAMFJREFUJr/M62Ls/Wn8zG4xGeO9r4CxIpIAICKxItIR5/torKvO1cB3qnoYOCgiw13l1wJfu2Z0SxORS137CBWRiDr9LYzxkn1DMcZLqrpBRB4E/isiAUAhcAtwFOekMg/ivOV0lWuTCcA/XQlgO6Ujt14LvOgahbMQuKIOfw1jvGajuRpTQyKSrapR/o7DmNpmt5iMMcZ4ZFcQxhhjPLIrCGOMMR5ZgjDGGOORJQhjjDEeWYIwxhjjkSUIY4wxHv0/afvmXmTxEsEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsHqkLAuf8pv"
      },
      "source": [
        "You might try to fine-tune the parameters (learning rate, batch size) a bit more if accuracy is not good enough.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HZb3NWFtFf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "So how good is our model on predicting sentiment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQ7-ylCj8Gd"
      },
      "source": [
        "We'll define a helper function to get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgR6MuNS8jr_"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbnBTI7kd_y"
      },
      "source": [
        "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdPZr60-0c_",
        "outputId": "8aea79c4-17bf-4270-d102-44b3b886c0e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFAekw3mmWUi"
      },
      "source": [
        "Let us compare true sentiment vs predicted sentiment by plotting a confusion matrix of `y_test` vs `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d1qxsc__DTh",
        "outputId": "149d7c71-587b-4531-97bd-bbf37ccdc784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        }
      },
      "source": [
        "# TODO. Q12. Plot the 3x3 confusion matrix and show that the model finds it a bit difficult to classify neutral reviews.\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_confusion_matrix(cm, savename, title='Confusion Matrix'):\n",
        "\n",
        "    plt.figure(figsize=(12, 8), dpi=100)\n",
        "    np.set_printoptions(precision=2)\n",
        "\n",
        "    # calculate the possibility value of each cell\n",
        "    ind_array = np.arange(len(class_names))\n",
        "    x, y = np.meshgrid(ind_array, ind_array)\n",
        "    for x_val, y_val in zip(x.flatten(), y.flatten()):\n",
        "        c = cm[y_val][x_val]\n",
        "        if c > 0.001:\n",
        "            plt.text(x_val, y_val, \"%0.2f\" % (c,), color='red', fontsize=15, va='center', ha='center')\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.binary)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    xlocations = np.array(range(len(class_names)))\n",
        "    plt.xticks(xlocations, class_names, rotation=90)\n",
        "    plt.yticks(xlocations, class_names)\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predict label')\n",
        "    \n",
        "    # offset the tick\n",
        "    tick_marks = np.array(range(len(class_names))) + 0.5\n",
        "    plt.gca().set_xticks(tick_marks, minor=True)\n",
        "    plt.gca().set_yticks(tick_marks, minor=True)\n",
        "    plt.gca().xaxis.set_ticks_position('none')\n",
        "    plt.gca().yaxis.set_ticks_position('none')\n",
        "    plt.grid(True, which='minor', linestyle='-')\n",
        "    plt.gcf().subplots_adjust(bottom=0.15)\n",
        "    \n",
        "    # show confusion matrix\n",
        "    plt.savefig(savename, format='png')\n",
        "    plt.show()\n",
        "\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "plot_confusion_matrix(matrix, 'confusion_matrix.png', title='confusion matrix')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WL5pDmvFyaU"
      },
      "source": [
        "### Predicting on Raw Text\n",
        "\n",
        "Let's use our model to predict the sentiment of some raw text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEPi7zQRsDhH"
      },
      "source": [
        "review_text = \"I love Deep Learning! Best course evah!!!1!!\""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et8xlDrKpH60"
      },
      "source": [
        "Use your trained model to predict the sentiment expressed in `review_text`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr_t3rUksumr",
        "outputId": "f6667ca1-4d66-4944-ab55-41ec9ee930ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO: Q13. Print the predicted sentiment in `review_text`.\n",
        "encoding = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "\n",
        "outputs = model(\n",
        "    input_ids=encoding['input_ids'].to(device), \n",
        "    attention_mask=encoding['attention_mask'].to(device)\n",
        "  )\n",
        "\n",
        "_, preds = torch.max(outputs, dim=1)\n",
        "print(\"The prediction of the reiew_text is:\", class_names[int(preds)])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction of the reiew_text is: positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf39tauBa2V2"
      },
      "source": [
        "## References\n",
        "\n",
        "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
        "- [L11 Language Models - Alec Radford (OpenAI)](https://www.youtube.com/watch?v=BnpB3GrpsfM)\n",
        "- [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "- [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/pdf/1905.05583.pdf)\n",
        "- [Huggingface Transformers](https://huggingface.co/transformers/)\n",
        "- [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
      ]
    }
  ]
}